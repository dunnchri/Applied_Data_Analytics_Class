{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy, Confidentiality and Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the exercises to the Privacy, Confidentiality and Ethics session. It provides a walkthrough of the disclosure review process and what you have to keep in mind when you want to export output. In addition, it provides examples of how research results can be biased (degradation) when working with modified (topcoded) data instead of using the original underlying information.\n",
    "\n",
    "### The notebook is outlined as follows: \n",
    "- [Data Preparation for Exercises](#Data-Preparation-for-Exercises)\n",
    "- [Exercise 1: Disclosure Review](#Exercise-1:-Disclosure-Review)\n",
    "- [How to Export Files](#How-to_Export-Files)\n",
    "- [Exercise 2: Degradation](#Exercise-2:-Degradation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "import sqlalchemy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Exercises\n",
    "This section creates variables and combines different datasets which are needed for the exercises later. From the IDES data we create a measure of total earnings and number of jobs people have in the first quarter of 2015. In a second step we censor these measures. From the IDOC data we will load individual characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = (os.getcwd())\n",
    "print(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "db_name = \"appliedda\"\n",
    "hostname = \"10.10.2.10\"\n",
    "conn = psycopg2.connect(database=db_name, host = hostname) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDOC data person file\n",
    "We need this data to obtain demographics for (ex-)offenders. These characteristics are standardized in the person table. We want to know when (ex-)offenders are born, their race and sex. In addition, we get the hashed SSN to identify their earnings' records in the IDES data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get data from person table (sex and race)\n",
    "query2 = 'SELECT ssn_hash, birth_year, race, sex FROM class1.person;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save query in dataframe\n",
    "df_ind = pd.read_sql( query2, con = conn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "df_ind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDES earnings file\n",
    "Form the IDES earnings file we get all earnings for the first quarter of 2015. This allows us to look at the entire working population of Illinois in the respective quarter, as well as all (ex-)offenders who have jobs in the first quarter of 2015 by merging this information to IDOC data. Thus, we need the hashed SSN and the wage variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all spell in 1st quarter of 2015 & variables needed\n",
    "query = 'SELECT ssn, wage FROM ides.il_wage WHERE year = 2015 AND quarter = 1;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save query in dataframe\n",
    "df_wage = pd.read_sql( query, con = conn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the data frame\n",
    "df_wage.sort_values(by='ssn')\n",
    "df_wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Number of Jobs \n",
    "We calculate the number of jobs each reported person has in the first quarter of 2015. Every job is reported separately so we just have to count the entries per ssn. Then we generate a variable number of jobs censored which we need for the degradation exercise. We censor the jobcount at three or more jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function for retrieving counts by group\n",
    "def get_count(group):\n",
    "    return{'count': group.count()}\n",
    "df_jobs=df_wage['wage'].groupby(df_wage['ssn']).apply(get_count).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and rename\n",
    "df_jobs = df_jobs.reset_index()\n",
    "df_jobs.rename(columns={'count':'nofjobs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate job variable info so we can censor one of them\n",
    "df_jobs['nofjobs_cens'] = df_jobs['nofjobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topcode number of jobs at 3\n",
    "df_jobs.loc[df_jobs['nofjobs_cens'] > 2, 'nofjobs_cens']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe \n",
    "df_jobs.sort_values(by='ssn')\n",
    "df_jobs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much jobs do people have in the reported quarter when using original measure?\n",
    "df_jobs['nofjobs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much jobs do people have in the reported quarter when using the topcoded measure?\n",
    "df_jobs['nofjobs_cens'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Wages\n",
    "Now we calculate the total earings for the first quarter in 2015 for every person because we want to find out more about earning inequality in Illinois. In addition, we generate a censored wage variable. Wages are censored at total earnings of ### USD per person per quarter. As we will be taking the log of earnings in the regressionns later we will replace 0 earnings with 0.0001 so we can create the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve sum of attribute by group\n",
    "def get_sum(group):\n",
    "    return{'sum': group.sum()}\n",
    "df_wage_tot=df_wage['wage'].groupby(df_wage['ssn']).apply(get_sum).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and rename\n",
    "df_wage_tot = df_wage_tot.reset_index()\n",
    "df_wage_tot.rename(columns={'sum':'wage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate wage info so we can censor one of the variables\n",
    "df_wage_tot['wage_cens'] = df_wage_tot['wage']\n",
    "# You cannot take the log of 0\n",
    "df_wage_tot.loc[df_wage_tot['wage'] == 0, 'wage']=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topcode earnings at #### USD\n",
    "df_wage_tot.loc[df_wage_tot['wage_cens'] > (###), 'wage_cens']=###\n",
    "# You cannot take the log of 0\n",
    "df_wage_tot.loc[df_wage_tot['wage_cens'] == 0, 'wage_cens']=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's look at the dataframe\n",
    "df_wage_tot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct final data for regressions\n",
    "This dataset contains all the information (earnings, jobcount, and demographics) for the population of ex-offenders who are employed in the first quarter of 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the wage andnumber of jobs info\n",
    "df_ides = pd.merge(left=df_wage_tot,right=df_jobs, how='inner', \n",
    "                   left_on=['ssn'], right_on=['ssn'])\n",
    "# Merge ides data to idc person data\n",
    "df_reg = pd.merge(left=df_ind,right=df_ides, how='inner', left_on=['ssn_hash'],\n",
    "                  right_on=['ssn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Disclosure Review\n",
    "This exercise provides you with information on how to prepare research output for disclosure control. It outlines different kind of output forms and what information is needed for disclosure review. In general you can export any kind of format. The most popular formats are tables, graphs, regression output and aggregated data. The only thing you can't export is content in a jupyter notebook. Durning the export process you have to provide the code for every output. Every result you would like to export needs to be saved in either .csv, .txt or graph format. It is not possible to do export reviews in a jupyter notebook.\n",
    "\n",
    "General Rules:\n",
    "- The disclosure review is based on the underlying observations. Every statistic you want to export should be based on at least 10 individual data points.\n",
    "- Document your code so the reviewer can follow your data work. Assessing re-identification risks highly depends on the context. Thus it is important that you provide content to your anlysis for the reviewer.\n",
    "- Save the requested output with the corresponding code in the git repo for your project's data exports. Make sure the code is executable. The code should exactly produce the output you requested.\n",
    "- In case you are exporting powerpoint slides that show project results you have to provide the code to produce the output in the slides. \n",
    "- Export results only when there are final and you need them for your report/work/presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables\n",
    "For tables of any kind you need to provide the underlying counts of the statistics presented in the table. Make sure you provide all counts. If you calculate ratios, for example re-incarceration rates, you need to provide the number of individuals who are incarcerated and then ones who are not. \n",
    "\n",
    "Let's assume we are intersted in demographic characteristics of ex-offenders and want to know how race and sex are distributed over birth year. We can get this information from the person table (df_ind, the dataframe which was created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's tabulate sex and race characteristics across birth_year\n",
    "print(pd.crosstab([df_ind.birth_year.fillna('missing'), df_ind.race.fillna('missing')], df_ind.sex.fillna('missing'), margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problematic Output\n",
    "We can see that we have a lot of small numbers here. This table won't be released. In this case, disclosure review would mean to delete all cells with counts of less than 10. In addition, secondary suppression has to take place. The disclosure reviewer has to delete as many cells as needed to make it impossible to recalculate the suppressed values. \n",
    "\n",
    "#### How to do it better\n",
    "Instead of asking for export of a tables like this, you should prepare your tables in advance that all cell sizes are at least represented by 10 observations. In our example we can do this by grouping birth years for instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate birth year variable\n",
    "cohort = []\n",
    "for row in df_ind['birth_year']:\n",
    "    if row < 1941:\n",
    "        cohort.append('up to 1939')\n",
    "    elif row > 1939 and row < 1960:\n",
    "        cohort.append('1940 to 1959')        \n",
    "    elif row > 1959 and row < 1980:\n",
    "        cohort.append('1960 to 1989')      \n",
    "    elif row > 1979 and row < 2000:\n",
    "        cohort.append('1970 to 1999')\n",
    "    else:\n",
    "        cohort.append('')\n",
    "df_ind['cohort']=cohort\n",
    "df_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's tabulate sex and race characteristics across cohort\n",
    "print(pd.crosstab([df_ind.cohort.fillna('missing'), df_ind.race.fillna('missing')], df_ind.sex.fillna('missing'), margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some small cell sizes, so this table needs even a higher aggregation. It would make sense to aggregate the race variable. For example, you can combine the races with small cell sizes into a group \"other\" or remove them from the table completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files: Tables and Aggregated Data\n",
    "You can save any dataframe as a csv file and export this csv file. The only thing you have to keep in mind is that besides the statistic X you are interested in you have to include a variable count of X so we can see on how many observations the statistic is based on. For example if you agregate by industry, we need to know how many observations are in each industry (after the aggregation each industry will be only one data point). This applies to all exported tables, aggregations, etc. For now let's save the table above in a .csv file to export the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include the races with enough observations\n",
    "output = df_ind[(df_ind.race == 'BLK') | (df_ind.race == 'HSP') | (df_ind.race == 'WHI')]\n",
    "# Produce crosstab\n",
    "export = pd.crosstab([output.cohort, output.race], output.sex, margins=True)\n",
    "print(export)\n",
    "# write to csv because notebook output cannot be exported\n",
    "export.to_csv('demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs\n",
    "It is important that every point which is plotted in a graph is based on at least 10 observations. Thus scatterplots for example cannot be released. In case you are interested in a histogram you have to change the bin size to make sure that every bin contains at least 10 people. In addition to the graph you have to provide the ADRF with the underlying table in a .csv or .txt file. This file should have the same name as the graph so ADRF can directly see which files go together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce plot for job count\n",
    "histjobs=df_jobs['ssn'].groupby(df_jobs['nofjobs']).apply(get_count).unstack()\n",
    "myplot = histjobs.plot(kind='bar', legend=None)\n",
    "myplot.set_ylabel(\"Total number of Workers\")\n",
    "myplot.set_xlabel(\"Number of Jobs held\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that there are only few people who had more than 3 jobs. Thus we have to make sure that we only plot the cells which contain more than 10 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the dataframe\n",
    "histjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dataframe with 10 plus observations\n",
    "histjobs_cens=histjobs[histjobs['count']>9]\n",
    "histjobs_cens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gernerate plot for export\n",
    "myplot2 = histjobs_cens.plot(kind='bar', legend=None)\n",
    "myplot2.set_ylabel(\"Total number of Workers\")\n",
    "myplot2.set_xlabel(\"Number of Jobs held\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot to file\n",
    "fig = myplot2.get_figure()\n",
    "fig.savefig('nofjobs_hist.png')\n",
    "# dont forget to save counts as csv with the same name as graph\n",
    "histjobs_cens.to_csv('nofjobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions\n",
    "You need to provide the ADRF with the number of observations which are included in the regression. When using the statsmodel package you can print the necessary information by using the summary command. Regression output should be written in a .txt file. If you are including dummies in the regression you need to provide the number of observations for each dummy included in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression on wages (not censored)\n",
    "model = smf.ols('log(wage) ~ C(sex) + C(race)', data= df_reg)\n",
    "results = model.fit()\n",
    "res = results.summary()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to find out the number of observations for each dummy\n",
    "counts = zip(model.exog.sum(0), model.exog_names)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write results in txt file\n",
    "output = open('OLS_results.txt', \"w\")\n",
    "output.write(\"%s\" % res + '\\n' \"%s\"  % counts)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Export Files\n",
    "Every project has a Git Repository which is only used for export request. The name of the repository is your project_name/export. You need to save every file that is includedd in an export request in this repository. After setting up the export git repo in your workspace please create two folders: input and output. \n",
    "- Save the code and any additional documentation for all your results you wnat to export in the input folder\n",
    "- Save the files that you wnat to export in the output folder. If you wnat to export a jupyter notebook please make sure that there is no data in the notebook before you put it in the output folder.\n",
    "\n",
    "When you are ready for export commit your changes to the repo and go to the gitlab interface, find your export repository and submit a merge request.\n",
    "- Press new merge request\n",
    "- Select the branch: export-yyyy-mm-dd\n",
    "- Select master as the branch\n",
    "- Fill out the necessary information:\n",
    "    - Title: export-yyyy-mm-dd-#-files\n",
    "    - Description: Provide us with a description of what is in the export request, what the purpose of the export is, what kind of files you are requesting and what kinf of analyis you performed. You should use this field to provide information in a way that a person who does not know what your project is about will be able to understand your output. The more detailed your description is the easier is it for the reviwer to understand what you did.\n",
    "\n",
    "When you merged the branch please notify us on the slack channel export-request that you want to request a disclosure review. Your slack message should only contain the project name and date of request. We then will look at the files and will be in touch with you about the export. \n",
    "\n",
    "ADRF reviews for confidentiality. Please keep in mind that some data providers might review your output too. Thus, the export process might take some time. To minimize our and the data providers work please only commit and export final results you need for your presentation and limit export of intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line: set up Git Repo and Commit/Push Files\n",
    "You need to clone the git repo and set up a branch. In a second step you need to create a subfolder input and a subfolder output in the export folder. Now you can add the files you want to export to the folders. Then you can commit and push your changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![easylink](./terminal1.jpg)\n",
    "![easylink](./terminal2.jpg)\n",
    "![easylink](./terminal3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gitlab: Sumit Merge Request\n",
    "Afer you committed and pushed you files to the export repo you can open gitlab and follow the procedure outlined below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find your export repository for your project project-project_name/export.\n",
    "![easylink](./gitlab1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on merge request.\n",
    "![easylink](./gitlab2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new merge request. The source branch should be your project export repo, which you label export-date. The target branch is master.\n",
    "![easylink](./gitlab3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press continue and you will be getting to following page. Her you need to provide us with information on your export request. Please fill out the fields before submitting your merge request. The assignee to enter is Daniela.\n",
    "![easylink](./gitlab4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting the request you will see the page below (without the accept button - this one is only available in the administrator interface). You have succesfully submitted output for disclosure review. \n",
    "![easylink](./gitlab5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please keep in mind that you will not recieve notifications through Git. After you submitted your merge request you need to send a message to the slack channel #export-request and let us know that output is waiting for us. Once the disclosure review is done ADRF will get in touch with you and send you the innformation needed to retrieve your output. \n",
    "\n",
    "In case your output doesn't pass the disclosure review we will let you know why and ask you to make changes to your results. You can commit these changes as amendment into the same branch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Degradation\n",
    "One way of protecting confidentiality in data is data transformation in such a way that information on the observed unit is reduced. Oftentimes this is done by adding noise, grouping of individual attributes, or topcoding. It is a common procedure done by data providers to generate public use files which can be freely accessed on the internet. These methods definitelyminimize the risk of re-identification, however, this data manipulation can also lead to wrong inference as the result do not necessarily represent the true underlying population. \n",
    "\n",
    "The goal of this excercise is to test how data manipulation can affect the result of a research project. We can demonstrate this by using the created topcoded variables on earnings and number of jobs. We execute two different kinds of analyses including the original and censored variable seperately and find out how much the results differ.\n",
    "\n",
    "The exercise is as follows: \n",
    "- How does manipulation of data affect regression output?\n",
    "- How does it affect the creation of an inequality measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Output: Original Value vs. Topcoded Value\n",
    "We will look at how regression out put changes when we use our two different neasures we constructed for the number of jobs and wages. We are interested in the relationship between number of jobs/total earnings and personal characteristics. This is using the combined dataset so we are looking at ex-offenders only. As they probably don't show earnings at the upper threshold we expect less differences when we regress on earnings compared to number of jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wages:\n",
    "# Run regression using the original measure\n",
    "results = smf.ols('log(wage) ~ C(sex) + C(race)', data= df_reg).fit()\n",
    "print(results.summary())\n",
    "print('Predicted values:')\n",
    "# Run regression using the topcoded measure\n",
    "results = smf.ols('log(wage_cens) ~ C(sex) + C(race)', data= df_reg).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs:\n",
    "# Run regression using the original measure\n",
    "results = smf.ols('nofjobs ~ C(sex) + C(race)', data= df_reg).fit()\n",
    "print(results.summary())\n",
    "# Run regression using the topcoded measure\n",
    "results = smf.ols('nofjobs_cens ~ C(sex) + C(race)', data= df_reg).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Coefficient: Original value vs. topcoded value\n",
    "The Gini coefficient is a measure of statisitcal dispersion to document the residents income/wealth/earnings distribution and is often used as a measure of inequality. A Gini of 0 denotes perfect equality, a Gini of 1 perfect inequality. We can calculate the Gini coefficient for the Illinois population and the population of ex-offerender. For the same reason as above we don't expect the Gini to differe much between censored and original variable within ex-offenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to calculate Gini Coefficient\n",
    "def gini(x):\n",
    "    n = len(x)\n",
    "    try:\n",
    "        x_sum = x.sum()\n",
    "    except AttributeError:\n",
    "        x = npasarray(x)\n",
    "        x_sum = x.sum()\n",
    "    n_x_sum = n * x_sum\n",
    "    r_x = (2. * np.arange(1, len(x)+1) * x[np.argsort(x)]).sum()\n",
    "    return (r_x - n_x_sum - x_sum) / n_x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Gini based on original value\n",
    "print('Gini Coefficient original earnings (all): ', gini(df_wage_tot['wage']))\n",
    "\n",
    "# Calculate Gini based on original value for ex-offenders\n",
    "print('Gini Coefficient original earnings (ex-offenders): ', gini(df_reg['wage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Gini based on censored value\n",
    "print('Gini Coefficient censored earnings (all): ', gini(df_wage_tot['wage_cens']))\n",
    "\n",
    "# Calculate Gini based on original value for ex-offenders\n",
    "print('Gini Coefficient censored earnings (ex-offenders): ', gini(df_reg['wage_cens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the inequality measure differs quite a bit when using the original reporting and a censored version of earnings for the working population of Illionis in the first quarter of 2015. In this case we would underreport earnings inequality which might lead to wrong policy advise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
