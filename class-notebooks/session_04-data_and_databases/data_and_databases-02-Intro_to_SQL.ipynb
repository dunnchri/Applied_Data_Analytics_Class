{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SQL\n",
    "\n",
    "Sourced largely from the CSSIP-AIR Big Data course's [Data and Databases](https://github.com/CSSIP-AIR/Big-Data-Workbooks/blob/master/02.%20Database%20Basics/Data_and_databases.ipynb) notebook.\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "\n",
    "    - [Learning objectives](#Learning-objectives)\n",
    "    - [Tables we will look at](#Tables-we-will-look-at)\n",
    "\n",
    "        - [Administrative data](#Administrative-data)\n",
    "\n",
    "            - [Illinois Department of Corrections exit dataset](#ildoc_exit)\n",
    "            - [IL DOC admissions](#ildoc_admit)\n",
    "            - [IL DOC parolee last known address](#il_doc_parole)\n",
    "            - [IL Department of Employment Security wage records](#il_wage)\n",
    "\n",
    "        - [Public data](#Public-data)\n",
    "\n",
    "            - [Zip code tabulation areas](#Zip-code-tabulation-areas)\n",
    "            - [Census Blocks](#Census-Block-polygons)\n",
    "\n",
    "- [Setup](#Setup)\n",
    "- [SQL basics](#SQL-basics)\n",
    "\n",
    "    - [Querying the database](#Querying-the-database)\n",
    "    - [**Exercise 1**](#Exercise-1)\n",
    "    - [WHERE clauses: Limiting the results](#WHERE-clauses:-Limiting-the-results)\n",
    "    - [**Exercise 2**](#Exercise-2)\n",
    "    - [JOIN: Connecting multiple tables](#JOIN:-Connecting-multiple-tables)\n",
    "    - [GROUP BY and aggregate functions](#GROUP-BY-and-aggregate-functions)\n",
    "    - [**Exercise 3**](#Exercise-3)\n",
    "    - [ORDER BY](#ORDER-BY)\n",
    "    \n",
    "- [PostGIS](#PostGIS)\n",
    "    - [PostGIS examples](#PostGIS-examples)\n",
    "    \n",
    "        - [Example 1: Points in polygons](#Example-1:-Points-in-polygons)\n",
    "        - [Example 2: Nearest neighbor distances](#Example-2:-Nearest-neighbor-distances)\n",
    "    \n",
    "- [Addendum - Other useful SQL](#Addendum---Other-useful-SQL)\n",
    "\n",
    "    - [Listing tables and columns](#Listing-tables-and-columns)\n",
    "    - [Modifying the database](#Modifying-the-database)\n",
    "    - [Coordinate-Reference Systems](#Coordinate-Reference-Systems)\n",
    "    - [Get spatial information from PostGIS](#Get-spatial-information-from-PostGIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this notebook, we will introduce structured query language (SQL).  SQL is the main way one interacts with relational databases.  SQL is much different from traditional programming languages.  A single SQL statement can contain the complexity of an entire Python or Java program, and the syntax initially seems relatively straightforward, but can quickly become confusing as you try more complicated queries.\n",
    "\n",
    "We will learn the basics of SQL, then use it to provide a pattern for exploring the class data sets, focusing on better understanding the Illinois Department of Corrections exit data and an open source database of zip code tabulation areas.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Learning objectives:\n",
    "\n",
    "- Become familiar with the basic syntax, structure, and uses of SQL.\n",
    "- Get some hands on experience writing and running SQL queries.\n",
    "- Use and learn descriptive SQL queries that can help you familiarize yourself with a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables we will look at\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this notebook, we will use tables in the \"`appliedda`\" database. These tables are based on data provided by a few different agencies: IL Department of Corrections, IL Department of Employment Statistics, US Department of Housing and Urban Development, and the U.S. Census Bureau.\n",
    "\n",
    "Specifically, we will be connecting to the \"`appliedda`\" database and looking at the \"`ildoc_admit`\", \"`ildoc_exit`\", and \"`il_wage`\" tablea, and the zip code table TK.  Basic information on these tables follows. \n",
    "\n",
    "### Administrative data\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "#### ildoc_admit\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This dataset includes admission data from the IL Department of Corrections from 1990 - 2015, that is: individual records of all people who were admitted to Illinois correctional facilities during that 16 year period. The data include many other fields of information (~170 total) including demographic data; charges and sentencing information; and conduct, security level, and health information. The full data description is available outside the ADRF on the course website, and inside the ADRF in the [ADRF Explorer](https://deepdish.adrf.info/detail/adrf-000001).\n",
    "\n",
    "#### ildoc_exit\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This dataset includes exit data from the IL Department of Corrections from 1990 - 2015, that is: individual records of all people who were released from Illinois correctional facilities during that 16 year period. The data include many other fields of information (~170 total) including admission dates, original and revised admission types, expected release dates, participation in programs offered by the correctional facility, and more. The full data description is available outside the ADRF on the course website, and inside the ADRF in the [ADRF Explorer](https://deepdish.adrf.info/detail/adrf-000002).\n",
    "\n",
    "#### il_doc_parole\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Location information for persons active in the Illinois parole system from 2009 to 2015. Note there are anumber of cautions associated with this data which can be found on the [ADRF Explorer](https://deepdish.adrf.info/detail/adrf-000036) page for this dataset.\n",
    "\n",
    "\n",
    "#### il_wage\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This dataset includes quarterly records of wages for every job held by each person in the state of Illinois from 2005 to 2015.  This data is derived from the Illinois Department of Employment Security (IDES) Unemployment Insurance (UI) wage file that the Local Employment Dynamics (LED) state partners supply to the Census department for use in producing Quarterly Workforce Indicators (QWI).  The full data description is available outside the ADRF on the course website.\n",
    "\n",
    "### Public data\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "#### Zip code tabulation areas\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Zip code tabulation areas (ZCTAs) are the same 5-digit zip codes everyone is used to, but only those which have a geographic boundary assigned to them (some zip codes represent specific buildings or entities so are technically contained within the boundary of a different zip code). This data will be useful when considering geographic distributions of ex-offenders.\n",
    "\n",
    "#### Census Block polygons\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Census Blocks are the smallest unit provided by the US Census and is designated by a 15 digit unique code known as its FIPS (Federal Information Processing Standard) code. Most geographic areas maintained by the federal government are simply groupings of Blocks and are used at varying levels depending on what analysis is being performed at what geographic scale. Geographic boundary files are provided for each of the following (and more):\n",
    "* `##` - state code (eg '17' for Illinois)\n",
    "* `###` - county code within a given state (eg '031' for Cook County in IL)\n",
    "* `###` - sub-county code within a given county\n",
    "* `###` - Tract code within a given sub-county (so to uniquely identify a Tract you need 11 digits)\n",
    "* `#` - Block Group code within a given Tract\n",
    "* `###` - Block code within a given Block Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Before you begin, make sure to pick a method of running SQL queries against the class database from the [Database clients notebook](./data_and_databases-Database_clients.ipynb) and get connected to the `appliedda` database.  If you are new to SQL, we recommend working with pgAdmin to start - it is the easiest and most intuitive of the ways you can run SQL in the ADRF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL basics\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "SQL is a quirky language. It is different from procedural languages like Python and is designed for a very specific purpose: to interact with relational data. It isn't structured like other languages, and while it can make data access easy, it also can make tasks that would be easy in other languages (though perhaps not exceptionally performant) confoundingly complex.  Let's dive in so you can see it for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The basic method of querying the database is to use a select statement:\n",
    "\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    LIMIT 1000; \n",
    "\n",
    "Where:\n",
    "\n",
    "- Columns or variables that would like returned are put in the SELECT clause (after the word \"SELECT\" but before the word \"FROM\").  An asterisk ( \"\\*\" ) is a wildcard - it will return all columns for a given table.\n",
    "- The name of the table (or names of the tables - more on this in a bit) you want to query is put after the word \"FROM\", in the FROM clause.\n",
    "- It is considered good style to capitalize words in an SQL query that are SQL words, not variables, table names, or values you are filtering on or searching for, ie. SELECT, FROM, WHERE, etc.\n",
    "- Although it isn't always necessary in PostgreSQL, you should end SQL statements with a semi-colon.  It isn't required everywhere, but it is required in some contexts so better to be aware and get into the habit.\n",
    "- \"`LIMIT 1000`\" is included throughout so we don't try to retrieve an entire table, in case our database client of choice loads results to memory.\n",
    "\n",
    "Instead of specifying “all” columns ( \"\\*\" ), you can specify which columns you want by name, in a comma-delimited list after \"SELECT\" (here adding admission year - curadmyr - and discharge year - actdisyr):\n",
    "\n",
    "    SELECT docnbr, curadmyr, actdisyr\n",
    "    FROM ildoc_exit\n",
    "    LIMIT 1000;\n",
    "\n",
    "You can specify calculations in the list of columns also (time in jail = discharge year - admission year):\n",
    "\n",
    "    SELECT docnbr, curadmyr, actdisyr, ( actdisyr - curadmyr )\n",
    "    FROM ildoc_exit\n",
    "    LIMIT 1000;\n",
    "\n",
    "And you can give those new columns names:\n",
    "\n",
    "    SELECT docnbr, curadmyr, actdisyr, ( actdisyr - curadmyr ) AS years_in_prison\n",
    "    FROM ildoc_exit\n",
    "    LIMIT 1000;\n",
    "    \n",
    "You can also use special keywords and functions in the SELECT clause.  For example, the keyword \"DISTINCT\", which only returns any given value in a given column once\n",
    "\n",
    "- use DISTINCT to only output each inmate's docnbr once, regardless of how many times they have been released from prison:\n",
    "\n",
    "        SELECT DISTINCT docnbr\n",
    "        FROM ildoc_exit\n",
    "        LIMIT 1000;\n",
    "    \n",
    "And the \"`COUNT()`\" aggregation function, passed a value that tells it what you want to count, which returns a count of matching rows rather than a list:\n",
    "\n",
    "- to just count rows that a query returns, pass count the argument \"`*`\".  **_Example:_** `COUNT` rows in `ildoc_exit`:\n",
    "\n",
    "        SELECT COUNT( * )\n",
    "        FROM ildoc_exit;\n",
    "\n",
    "- to count `DISTINCT` values, include the `DISTINCT` part of your SELECT clause inside the call to `COUNT()`.  **_Example:_** `COUNT` `DISTINCT` inmate IDs (docnbr) in `ildoc_exit`:\n",
    "\n",
    "        SELECT COUNT( DISTINCT docnbr )\n",
    "        FROM ildoc_exit;\n",
    "    \n",
    "Also SQL has various \"aggregation\" functions (`COUNT()` is one) which return a single value for a given input group, for example you can find the minimum (`MIN()`), maximum (`MAX()`), and average (`AVG()`) of numeric values:\n",
    "\n",
    "    SELECT MIN( curadmyr ) AS earliest_admission_yr, MAX( curadmyr ) AS latest_admission_yr\n",
    "    FROM ildoc_exit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Use your database client of choice to interact with the database to answer the questions that follow.\n",
    "\n",
    "For each question, enter:\n",
    "\n",
    "- The SQL query you used to find the answer.\n",
    "- The answer to the question.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- 1) Find the number of distinct ex-offenders in the `ildoc_exit` database table.\n",
    "- 2) Find the number of distinct zipcodes in the `ildoc_exit` database table.\n",
    "\n",
    "Example code:\n",
    "\n",
    "    SELECT COUNT( DISTINCT( docnbr ) ) AS docnbr_count\n",
    "    FROM ildoc_exit;\n",
    "\n",
    "### Exercise 1 work space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E1-Q1-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 - Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E1-Q1-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E1-Q2-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 - Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E1-Q2-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE clauses: Limiting the results\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In a SELECT query, you can add a WHERE clause to limit the results (here, limiting to just inmates admitted in 2014):\n",
    "\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE curadmyr = 2014\n",
    "    LIMIT 1000;\n",
    "\n",
    "Where:\n",
    "\n",
    "- you are making conditional tests, just like in a Python \"if\" statement.\n",
    "- EXCEPT here, instead of \"==\" being the equality operator, it is just \"=\".\n",
    "- Comparison operators:\n",
    "\n",
    "    - \"**_`=`_**\" - equal to\n",
    "    - \"**_`!=`_**\" or \"**_`<>`_**\" - not equal to\n",
    "    - \"**_`<`_**\" - less than\n",
    "    - \"**_`<=`_**\" - less-than-or-equal-to\n",
    "    - \"**_`>`_**\" - greater than\n",
    "    - \"**_`>=`_**\" - greater-than-or-equal-to\n",
    "    - \"**_`LIKE`_**\" and \"**_`NOT LIKE`_**\" - wild-card matching operator, where percent matches 0 or more characters ( \"%\" ) and an underscore matches any 1 character ( \"_\" ).\n",
    "    - \"**_`IN( value_list )`_**\" and \"**_`NOT IN( value_list )`_**\" - checks whether the value to the left of the \"IN\", usually a column's value in a given row, is either IN or NOT IN the list on the right of the IN.\n",
    "    \n",
    "An example of using LIKE (include only zip codes that start wth \"606\" - Chicago):\n",
    "\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE zipcode LIKE '606%'\n",
    "    LIMIT 1000;\n",
    "\n",
    "You can specify multiple conditions for matching in your WHERE clauses, as well, to more precisely filter the results of your query:\n",
    "\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE curadmyr = 2014 AND admtypr IN ('DFC', 'MVN')\n",
    "    LIMIT 1000;\n",
    "    \n",
    "Note:\n",
    "\n",
    "- when you are matching a column whose type is numeric, you just put the value in the query, with no quotation marks (just like in Python).\n",
    "- when you are filtering a string column, you have to include the value you are looking for (the value on the right-hand side of the equal sign) in single-quotes. They must be single-quotes, too.  Unlike in Python, double-quotes have an entirely different meaning than single quotes in SQL, and can cause your query to fail.\n",
    "\n",
    "Like \"None\" in Python, the signifier of an unset value in a column for a row is special - NULL.  To check for NULL, you use \"IS NULL\" or \"IS NOT NULL\", rather than the \"=\" or \"!=\".\n",
    "\n",
    "    /* find missing values */\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE exityr IS NULL\n",
    "    LIMIT 1000;\n",
    "\n",
    "You can also explicitly cut off the number of results your query returns using the LIMIT keyword.  Just LIMITing to 10 only returns the first 10 results for the query:\n",
    "\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE curadmyr = 2014 AND admtypr IN ('PVN', 'TPV')\n",
    "    LIMIT 10;\n",
    "    \n",
    "You can also use LIMIT with OFFSET to skip a given number of records. The OFFSET value is the number to skip and LIMIT restricts the number of values returned.\n",
    "\n",
    "    /* skip 10, the output 15 */\n",
    "    SELECT *\n",
    "    FROM ildoc_exit\n",
    "    WHERE curadmyr = 2014 AND admtypr IN ('PVN', 'TPV')\n",
    "    OFFSET 10 LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Use your database client of choice to interact with the database to answer the questions that follow.\n",
    "\n",
    "For each question, enter:\n",
    "\n",
    "- The SQL query you used to find the answer.\n",
    "- The answer to the question.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- 3) Using any row in the ildoc_exit table that is assigned revised admission type (`admtypr`) \"PVN\" (parole violation, new sentence), how many years were served?\n",
    "- 4) Using the rows in the ildoc_exit table that refers to revised admission type (`admtypr`) \"PVN\" and exit year after 1994, what is the average duration of time spent in prison?\n",
    "\n",
    "Example code:\n",
    "\n",
    "    SELECT curadmyr, exityr\n",
    "    FROM ildoc_exit\n",
    "    WHERE admtypr = 'PVN'\n",
    "    LIMIT 1;\n",
    "\n",
    "### Exercise 2 work space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E2-Q3-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 - Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E2-Q3-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E2-Q4-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 - Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E2-Q4-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOIN: Connecting multiple tables\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "We can specify multiple tables in the FROM clause of a select query. This is called a “JOIN”. However, when we do, we need to remember to specify how to match up rows across the two tables. Usually, there is a column that is the same in both tables that can be used to match them up. For much of the course data that will be the hash values of individual's names and SSN.\n",
    "\n",
    "For examples of joining on SSN hashes, we will now look at the `ildoc_admit` table, which has SSN where `ildoc_exit` does not, and the `il_wage` table.  To start, find wage records that match inmate records based on having the same SSN hash:\n",
    "\n",
    "    /* Lists earnings of 10 matching records */\n",
    "    SELECT ia.id AS admit_id, ia.docnbr, iw.id AS wage_id, iw.wage, iw.year, iw.quarter\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    LIMIT 10;\n",
    "\n",
    "Also, as you can see in the above example, in more complex queries we often give tables temporary short names to make it easy to refer to them.  Temporary short names are added after a given table's name in the FROM clause, separated by a space.  Example: \"ia\" in \"`FROM ildoc_admit ia`\".\n",
    "\n",
    "We can still use regular WHERE clauses in these queries, too, to further filter:\n",
    "\n",
    "    /* Lists earnings of matching records where individual admitted for violating parole */\n",
    "    SELECT ia.id AS admit_id, ia.docnbr, ia.admtypo, ia.curadmyr, iw.id AS wage_id, iw.wage, iw.year, iw.quarter\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    WHERE ia.admtypo = 'PVN'\n",
    "    LIMIT 10;\n",
    "\n",
    "You can also join more than two tables if you like.\n",
    "\n",
    "The ability to easily join data from multiple tables together using SQL is one of the most important and useful features of relational databases.  Complex relational data can be broken up into table designs that model the entities and transactions within a system, grouping like information and minimizing repitition, but then SQL allows data from these tables to be combined and flattened to form all kinds of tabular data outputs that are easily used for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROUP BY and aggregate functions\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Often, one thing that you want to do is to aggregate over multiple rows. For example, \"What are the average earnings for each admission type in 2010?\" To do this, use a GROUP BY clause:\n",
    "\n",
    "    /* Average earnings by revised admission type of matching records for individuals admitted in 2010 */\n",
    "    SELECT ia.admtypo, AVG( iw.wage ) AS average_earnings\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    WHERE ia.curadmyr = 2010\n",
    "    GROUP BY ia.admtypo;\n",
    "\n",
    "_Note: this query might take a minute or two to complete because of the size of the wage table._\n",
    "\n",
    "There are a number of useful aggregate functions:\n",
    "\n",
    "- **_SUM( column )_** : Calculate the sum of column for all the rows in each group\n",
    "- **_AVG( column )_** : Calculate the numeric average for all of the rows in each group\n",
    "- **_COUNT( column )_** : Count the number of rows in each group\n",
    "- **_MIN( column ) and MAX( column )_** : Find the minimum or maximum value of column in all the rows in each group\n",
    "\n",
    "Often, it can be very powerful to combine GROUP BY and table joins, but the queries can quickly become complicated. To simplify the process of building queries that combine GROUP BY and JOIN, first create an SQL query that JOINs correctly to return the individual rows you want to GROUP, then add the aggregate function calls to the SELECT clause and GROUP BY to the end of the SQL statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Use your database client of choice to interact with the database to answer the questions that follow.\n",
    "\n",
    "For each question, enter:\n",
    "\n",
    "- The SQL query you used to find the answer.\n",
    "- The answer to the question.\n",
    "\n",
    "Questions:\n",
    "\n",
    "- 5) Based on information in ildoc_exit, how many individuals were released from IL correctional facilities in 2013? \n",
    "- 6) How many individuals were released for each year from 2010-2015?\n",
    "- 7) How long was the average individual who was released in 2014 in prison for each revised admission type?\n",
    "\n",
    "Example code:\n",
    "\n",
    "    SELECT COUNT( * ) AS number_released\n",
    "    FROM ildoc_exit\n",
    "    WHERE exityr = 2012;\n",
    "\n",
    "### Exercise 3 work space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q5-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 - Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q5-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q6-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6 - answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q6-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7 - SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q7-SQL",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7 - answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "E3-Q7-answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORDER BY\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "When an SQL query is run, the results are not guaranteed to return in any set order, though basic single-table queries oftern return rows in the order they appear in the database. \n",
    "\n",
    "If you want your results ordered a certain way, you use an `ORDER BY` clause to tell the database how to order the rows in the results of a given query.\n",
    "\n",
    "> Aside: the below queries make use of using an alias for tables and renaming some columns. In the `SELECT` portion of the following query the optional keyword `AS` is used for legibility, whereas the DOC admissions and IL wage record tables are assigned an alias without the `AS` by simply adding a name directly after the table (`ia` and `iw` below, respectively).\n",
    "\n",
    "A single column example (`ORDER BY` docnbr):\n",
    "\n",
    "    SELECT ia.id AS admit_id, ia.docnbr, iw.id AS wage_id, iw.wage, iw.year, iw.quarter\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    ORDER BY ia.docnbr\n",
    "    LIMIT 1000;\n",
    "\n",
    "In an `ORDER BY` clause one can specify a list of the columns you want to sort the results on, in the order they appear in the list.  The database will first order the rows based on the values in the left-most item in the `ORDER BY` list.  Then as it moves left-to-right through the `ORDER BY` list, when there are duplicates in a given column, if there is another column name in the list to the right of the current column, it will order each set of rows with duplicate values based on the next column named in the `ORDER BY` list.\n",
    "\n",
    "For example, if you ORDER BY docnbr, then year, then quarter:\n",
    "\n",
    "    SELECT ia.id AS admit_id, ia.docnbr, iw.id AS wage_id, iw.wage, iw.year, iw.quarter\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    ORDER BY ia.docnbr, iw.year, iw.quarter\n",
    "    LIMIT 1000;\n",
    "\n",
    "If there are multiple rows for a given inmate (docnbr), then this query will order the rows for that inmate by year, ascending.  If there are multiple for a given year, the rows for a given year will be ordered by quarter within that year, ascending.\n",
    "\n",
    "By default, rows are ordered in ASCending order.  After you specify a given column to `ORDER BY`, you can optionally specify either ASC for ascending order, or DESC for descending order.\n",
    "\n",
    "Using `ORDER BY` with custom column names can be really useful when combined with `GROUP BY`:\n",
    "\n",
    "    /* Average earnings by admission type of matching records for individuals admitted in 2010 \n",
    "        order results from highest to lowest earnings */\n",
    "    SELECT ia.admtypo, AVG( iw.wage ) AS average_earnings\n",
    "    FROM ildoc_admit ia\n",
    "    JOIN il_wage iw\n",
    "    ON ia.ssn_hash = iw.ssn\n",
    "    WHERE ia.curadmyr = 2010\n",
    "    GROUP BY ia.admtypo\n",
    "    ORDER BY average_earnings DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More questions\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In addition to the exercises above, if you'd like to try to answer more of our questions with SQL before you dive into project work, here once again are the questions asked in the pandas introduction notebook:\n",
    "\n",
    "- The table `ildoc_admit` contains a field `escrisk` which stands for escape risk. The categories are:\n",
    "\n",
    "    - H: High\n",
    "    - M: Moderate\n",
    "    - L: Low\n",
    "    - P: Pending\n",
    "\n",
    "    Find the number individuals in `il_admit` with each of these levels of escape risk during the year 2014.  \n",
    "    \n",
    "- What is the maximum number of admits a single prisoner has had in the ildoc system?  Let's group the records by the docnbr, then count the number of records in each group.  Sort the values from highest to least, and then get the top value. Which prisoner has the highest number of admits?\n",
    "\n",
    "- Find the mean, median and minimum value of the number of times each individual prisoner in the ildoc system was admitted to prison.\n",
    "\n",
    "- Find the distribution of admit counts by year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "# PostGIS\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The PostGIS extension to PostgreSQL provides a very rich library of spatial functions which can be used directly in the database, and more functionality is added frequently by the community of developers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostGIS examples\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Let's combine some of our newfound database knowledge with a few common spatial analysis tasks: (1) how many _things_ are in a given area? (2) how far are _some things_ from _some other things_? and (3) how many _other things_ are within some distance? We'll use the parolees, HUD programs, and Census tract datasets in the examples.\n",
    "\n",
    "1. Question 1: Which Census Blocks in Chicago had the most parolees in 2015?\n",
    "2. Question 2: How far are parolees from the nearest HUD program?\n",
    "3. Question 3: Which 10 parolees' have the most households participating in a HUD program within 5 miles in 2014?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Points in polygons\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**Question 1**: Which Census Blocks had the most parolees in 2015?\n",
    "\n",
    "The two datasets used in the first analysis are\n",
    "+ Parolees' last know addresses from IL DOC - these data include latitude and longitude coordinates from geocoding with the Census TIGER\\Lines data and 85.2% of records were matched at the address level (code snippet below shows geocoding accuracy breakdown)\n",
    "+ Census Blocks - polygons of census Blocks for 2016, subset to Chicago Metropolitan area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLAlchemy for database connection\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# set database connection\n",
    "conn = create_engine('postgresql://10.10.2.10/appliedda')\n",
    "\n",
    "# pandas for easy data querying\n",
    "import pandas as pd\n",
    "\n",
    "# get number of records by accuracy of geocoded parolee addresses #\n",
    "qry = \"SELECT geocode_level, count(*) recs FROM il_doc_parole GROUP BY geocode_level ORDER BY recs DESC;\"\n",
    "geocode_accuracy = pd.read_sql(qry, conn)\n",
    "\n",
    "# calculate percentage for each geocode_level\n",
    "geocode_accuracy['percent'] = geocode_accuracy.recs / geocode_accuracy.recs.sum() *100\n",
    "\n",
    "# print resulting dataframe\n",
    "geocode_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of distinct tasks we will have the database perform all as one query:\n",
    "1. Subset the parolee locations to only those in 2015 (in the `WHERE` clause)\n",
    "2. Join the parolee data with the Block data (in the `FROM` clause)\n",
    "4. Summarize by block and count the number of parolees (the `GROUP BY` clause coupled with the `count()` aggregator)\n",
    "5. Show only the top 10 blocks by the count of parolees (using `ORDER BY` and `LIMIT`)\n",
    "\n",
    "First, we set up the query:\n",
    "\n",
    "    /* select Block codes and count the number of parolees in each Block */\n",
    "    SELECT b.geoid10 block_code, count(p.*) parolee_count\n",
    "\n",
    "    /* set input datasets \"b\" from the Block data for Chicago and \"p\" for parolee data */\n",
    "    FROM tl_2016_16980_tabblock10 b\n",
    "    JOIN il_doc_parole p\n",
    "    \n",
    "    /* join the tables on their geographic relationship, here that parolee locations are within Blocks */\n",
    "    ON ST_Within(p.geom, b.geom)\n",
    "\n",
    "    /* filter parolee data using to just 2015 */\n",
    "    WHERE p.year = 2015\n",
    "\n",
    "    /* filter out rows where origin and destination are the same zip code. */\n",
    "    GROUP BY b.geoid10\n",
    "\n",
    "    /* and let's order by distance so the output is easier to view */\n",
    "    ORDER BY parolee_count DESC\n",
    "    \n",
    "    /* only show the top 10 Blocks by parolee count*/\n",
    "    LIMIT 10;\n",
    "\n",
    "Here's the query all together:\n",
    "\n",
    "    SELECT b.geoid10 block_code, count(p.*) parolee_count\n",
    "    FROM tl_2016_16980_tabblock10 b JOIN il_doc_parole p\n",
    "    ON ST_Within(p.geom, b.geom)\n",
    "    WHERE p.year = 2015\n",
    "    GROUP BY b.geoid10\n",
    "    ORDER BY parolee_count DESC\n",
    "    LIMIT 10;\n",
    "    \n",
    "The above query orders by decreasing parolee counts.  If we wanted to see Blocks with the fewest parolees first:\n",
    "\n",
    "    SELECT b.geoid10 block_code, count(p.*) parolee_count\n",
    "    FROM tl_2016_16980_tabblock10 b JOIN il_doc_parole p\n",
    "    ON ST_Within(p.geom, b.geom)\n",
    "    WHERE p.year = 2015\n",
    "    GROUP BY b.geoid10\n",
    "    ORDER BY parolee_count\n",
    "    LIMIT 10;\n",
    "\n",
    "And we could always use LIMIT to a different number, or remove the limit all together to return any Block with at least one parolee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Nearest neighbor distances\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In the next question we will again use the Parolee dataset, and additionally we will use the HUD program data. Specifically, we will use the HUD program Block codes (`block_id`) and total households (`hh_tot`) to get a sense of how many households were enrolled in the nearest HUD program for each parolee.\n",
    "\n",
    "Again there are multiple tasks we will perform all within a single query:\n",
    "1. Use only parolee and HUD data from 2014 and only parolee where `geocode_level = 'address'`,\n",
    "2) Subset the datasets to only \n",
    "4) Calclate the distances between parolee and HUD locations\n",
    "5) Keep only distinct records of parolees and the closest HUD location\n",
    "\n",
    "**Question 2**: How far were parolees from the nearest HUD program in 2014?\n",
    "\n",
    "    /* select the unique records of parolees, their Unique identifier, number of HH in this Block, and the distance between the parolees' locations and the nearest Block centroid that has HUD participating households */\n",
    "    SELECT DISTINCT ON (p.id) p.person_id, h.hh_tot, ST_Distance(p.geom, h.geom) AS distance\n",
    "\n",
    "    /*** define the input ***/\n",
    "    /* parolee data and HUD data */\n",
    "    FROM il_doc_parole AS p, hud_household_block_data AS h\n",
    "    \n",
    "    /* consider only the 2014 records for each dataset, only parolee locations that successfully geocoded, and HUD household data that has Block level locations */\n",
    "    WHERE year = 2014 AND geocode_level = 'address' AND h.admin_yr = 2014 AND h.geom IS NOT NULL\n",
    "\n",
    "\n",
    "    /* ORDER BY p.id so that DISTINCT works and second by distance to only retain the closest HUD records; LIMIT to just 10 so thousands of records are not printed out (~25k parolee addresses in 2014): */\n",
    "    ORDER BY p.id, distance \n",
    "    LIMIT 10;\n",
    "\n",
    "So, here's a compacted version of the query that we could copy and run (BUT DON'T, it's slow):\n",
    "\n",
    "    SELECT DISTINCT ON (p.id) p.person_id, h.hh_tot, ST_Distance(p.geom, h.geom) AS distance\n",
    "    FROM il_doc_parole AS p, hud_household_block_data AS h\n",
    "    WHERE year = 2014 AND geocode_level = 'address' AND h.admin_yr = 2014 AND h.geom IS NOT NULL\n",
    "    ORDER BY p.id, distance \n",
    "    LIMIT 10;\n",
    "    \n",
    "The above query takes ~5-10 minutes to complete. Why? Because it needs to calculate the distance between all the ~24k parolee locations and ~6.5k HUD Blocks (after the filters in the `WHERE` clause).\n",
    "\n",
    "Using psql the above query looks like this:\n",
    "\n",
    "    appliedda=> SELECT DISTINCT ON (p.id) p.person_id, h.hh_tot, ST_Distance(p.geom, h.geom) AS distance\n",
    "    appliedda->     FROM il_doc_parole AS p, hud_household_block_data AS h\n",
    "    appliedda->     WHERE year = 2014 AND geocode_level = 'address' AND h.admin_yr = 2014 AND h.geom IS NOT NULL\n",
    "    appliedda->     ORDER BY p.id, distance \n",
    "    appliedda->     LIMIT 10;\n",
    "     \n",
    "     -- and output will look something like the below\n",
    "     person_id | hh_tot |       distance       \n",
    "    -----------+--------+----------------------\n",
    "             xx |    xx      xx\n",
    "             xxxxxxxxxxxxxxxxxxxx\n",
    "             xxxxxxxxxxxxxxxxxxxx\n",
    "             xxxxxxxxxxxxxxxxxxxx\n",
    "             xxxxxxxxxxxxxxxxxxxx\n",
    "    (10 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above distances the values are...  difficult to interpret. This is because of geographic projections (aka Coordinate Reference Systems or CRS, see the [addendum](#Addendum---Some-other-useful-SQL-+-Python-snippets)). The geometry column we used ('geom') is in projection \"NAD83\" so the resulting distances are in \"degrees\". Let's redo it with the US Atlas projection which is in meters, column \"geom_2163\" for parolee data and \"geom_pnt_2163\" for HUD data (this is actually the centroid of the associated Block).\n",
    "\n",
    "Note: please see the [Add spatial info](../../data/Add-spatial-info-to-appliedda-tables.ipynb) notebook in the `data` folder for details of how geometries were added to these tables.\n",
    "\n",
    "So, let's redo the query but make the distances more useful. Additionally we are going to `JOIN` the tables based on a distance parameter so the database does not need to calculate all ~24k * ~6k distances - check out the difference in the `FROM` clause below with the previous query above. The `ST_DWithin()` function returns `TRUE` when the first geometry is within the specified distance of the second geometry, below it is set to two miles (since our projection is in meters, we multiply 1609.344 by the number of miles we want).\n",
    "\n",
    "    SELECT DISTINCT ON (p.id) p.person_id, h.hh_tot, ST_Distance(p.geom_2163, h.geom_pnt_2163)/1609.344 AS distance_miles\n",
    "    FROM il_doc_parole AS p\n",
    "    JOIN hud_household_block_data AS h\n",
    "    ON ST_DWithin(p.geom_2163, h.geom_pnt_2163, 5*1609.344)\n",
    "    WHERE year = 2014 AND geocode_level = 'address' \n",
    "        AND h.admin_yr = 2014 AND h.geom_pnt_2163 IS NOT NULL\n",
    "    ORDER BY p.id, distance_miles\n",
    "    LIMIT 10;\n",
    "\n",
    "Now the distances are much more readily interpretable as miles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "# Addendum - Other useful SQL\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Below are a handful of examples which may be useful:\n",
    "\n",
    "1. [Listing tables and columns](#Listing-tables-and-columns)\n",
    "2. [Modifying a database](#Modifying-the-database)\n",
    "2. [Coordinate Reference Systems](#Coordinate-Reference-Systems)\n",
    "3. [Get spatial information from PostGIS](#Get-spatial-information-from-PostGIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing tables and columns\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "- Back to the [Addendum](#Addendum---Other-useful-SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that can be useful is seeing what tables (and views etc) exist in a database. PostgreSQL has a few different places to get information about what exists in the database, but in the following example we will make use of the `pg_class` table.\n",
    "\n",
    "Task: list all tables that start with \"il\":\n",
    "\n",
    "    SELECT relname, relkind\n",
    "    FROM pg_class\n",
    "    WHERE relname LIKE 'il%';\n",
    "    \n",
    "Limit to only tables (relkind = 'r'):\n",
    "\n",
    "    SELECT relname, relkind\n",
    "    FROM pg_class\n",
    "    WHERE relname LIKE 'il%'\n",
    "    AND relkind = 'r';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the database\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "- Back to the [Addendum](#Addendum---Other-useful-SQL)\n",
    "\n",
    "In addition to retrieving information from an existing database, you can also insert data into a database, update existing rows, and delete records using SQL. Permissions on databases generally will not allow you to modify the databases, but below are example queries of how you could modify a database to which you have 'WRITE' permission.\n",
    "\n",
    "Here are some example queries:\n",
    "\n",
    "- **CREATE**: Adding a table to a database\n",
    "\n",
    "        CREATE TABLE data (\n",
    "        ID int(11) serial primary key, \n",
    "        name_first varchar(20)\n",
    "        name_last varchar(30))\n",
    "\n",
    "- **INSERT**: Adding a row to a table\n",
    "\n",
    "        INSERT INTO data\n",
    "        (name_first, name_last)\n",
    "        VALUES ('Christina', 'Jones')\n",
    "\n",
    "- **UPDATE**: Changing data that is already in a table\n",
    "\n",
    "        UPDATE data\n",
    "        SET name_last = 'Johnson'\n",
    "        WHERE name_first = 'Christina'\n",
    "        \n",
    "- **ALTER TABLE**: Changing the structure of an existing table\n",
    "\n",
    "        ALTER TABLE data\n",
    "            ADD COLUMN gender VARCHAR(1) DEFAULT 'F'\n",
    "\n",
    "- **DELETE**: Removing one or more rows from a table\n",
    "\n",
    "        DELETE FROM cjones.data\n",
    "        WHERE name_last = 'Johnson'\n",
    "\n",
    "- **DELETE**: removing table from database\n",
    "\n",
    "        DROP TABLE cjones.data\n",
    "\n",
    "\n",
    "Lastly, you can also CREATE a table using an existing table. \n",
    "\n",
    "- **CREATE**: Adding a table to a database (NOTE: creating a table this way is one of the few times **`as`** is required by PostgreSQL)\n",
    "\n",
    "        CREATE TABLE parole_violator_exit_2012 AS (\n",
    "        SELECT * FROM ildoc_exit\n",
    "        WHERE exityr = 2012\n",
    "        and admtypr IN ('PVN', 'TPV'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Reference Systems\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "- Back to the [Addendum](#Addendum---Other-useful-SQL)\n",
    "\n",
    "This is an extremely brief overview of Coordinate Reference Systems (\"CRS\", also known as \"projections\"). Because Earth is a spheroid (like a sphere, but problematically bumby) people have created a lot of ways to deal with representing Earth's three dimensional surface in flat, two-dimensional space. Projections are basically math that (1) describes how information in a given dataset relates to the rest of the world and (2) usually creates a 'flat' surface on which data can be analyzed using more common algorithms (eg Euclidean geometry). \n",
    "\n",
    "A projection has two main components:\n",
    "\n",
    "1. The \"datum\" provides the context of where in the world the projection applies. The two most common in the US are WGS84 (World Geodesic Survey of 1984 - if you know your home or city latitude and longitude it's probably in WGS84) and NAD83 (North American Datum 1983), and\n",
    "2. The transformation algorithm - this has many parts that we don't need to cover here. If you're interested in learning more here's a couple resources: [NOAA tutorial](https://coast.noaa.gov/digitalcoast/training/datums.html) and [ArcGIS description](http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=About%20map%20projections)\n",
    "\n",
    "Here's some examples of global projections (thanks to [xkcd](https://xkcd.com/977/)):\n",
    "![map-projections](./images/map_projections_xkcd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different continental, regional, and country specific projections created by different agencies. The international spatial data and analysis community has created standard set of codes to easily tell different software programs what reference system your data are in or to which projection you are transforming your data.\n",
    "A couple good resource for finding coordinate reference systems are [epsg.io](http://epsg.io/) and [spatialreference.org](http://spatialreference.org/).\n",
    "\n",
    "If you get spatial data from somewhere, the metadata **_should_** include what Reference System the data are in. If your data are delivered as a `shapefile` (which is actually a collection of at least 4 individual files) then the `.prj` file includes the projection definition in \"well known text\" (WKT) format, in PostGIS this looks something like:\n",
    "\n",
    "    GEOGCS[\"NAD83\",\n",
    "        DATUM[\"North_American_Datum_1983\",\n",
    "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
    "                AUTHORITY[\"EPSG\",\"7019\"]\n",
    "            ],\n",
    "            TOWGS84[0,0,0,0,0,0,0],\n",
    "            AUTHORITY[\"EPSG\",\"6269\"]\n",
    "        ],\n",
    "        PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]\n",
    "    ],\n",
    "    UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4269\"]]\n",
    "\n",
    "Another common way programs understand projections is in what's called the \"proj4\" format, in PostGIS it looks like this:\n",
    "\n",
    "    +proj=longlat +datum=NAD83 +no_defs\n",
    "    \n",
    "PostGIS handles projections via some math and programming we don't need to worry about here and the `spatial_ref_sys` table (ie \"spatial reference systems\"), which contains both the WKT and proj4 definitions as well as a unique identifier: `srid`. Generally the `spatial_ref_sys` table is populated with many (~3-4 thousand) projections, however sometimes data will come in a format unknown to the database. If that happens you can usually find an `INSERT` statement on epsg.io to add the projection to your database. Here's what that looks like for the \"NAD83 / New York Long Island (ft)\" coordinate system:\n",
    "\n",
    "    INSERT into spatial_ref_sys (srid, auth_name, auth_srid, proj4text, srtext) \n",
    "        values ( 2263, 'EPSG', 2263, \n",
    "            '+proj=lcc +lat_1=41.03333333333333 +lat_2=40.66666666666666 +lat_0=40.16666666666666 +lon_0=-74 \n",
    "                +x_0=300000.0000000001 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=us-ft +no_defs ', \n",
    "            'PROJCS[\"NAD83 / New York Long Island (ftUS)\",GEOGCS[\"NAD83\",\n",
    "                DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
    "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
    "                TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,\n",
    "                AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "                AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],\n",
    "                PARAMETER[\"standard_parallel_1\",41.03333333333333],\n",
    "                PARAMETER[\"standard_parallel_2\",40.66666666666666],\n",
    "                PARAMETER[\"latitude_of_origin\",40.16666666666666],PARAMETER[\"central_meridian\",-74],\n",
    "                PARAMETER[\"false_easting\",984250.0000000002],PARAMETER[\"false_northing\",0],\n",
    "                UNIT[\"US survey foot\",0.3048006096012192,AUTHORITY[\"EPSG\",\"9003\"]],\n",
    "                AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],\n",
    "                AUTHORITY[\"EPSG\",\"2263\"]]'\n",
    "        );\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get spatial information from PostGIS\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "- Back to the [Addendum](#Addendum---Other-useful-SQL)\n",
    "\n",
    "In PostGIS the `geometry_columns` view maintains information about what geometry data exists in the tables in the database, so there's a simple way to see _all_ the tables that have spatial data like so:\n",
    "\n",
    "    SELECT f_table_name\n",
    "    FROM geometry_columns\n",
    "    GROUP BY f_table_name\n",
    "    ORDER BY f_table_name;\n",
    "    \n",
    "And there is also a way to see what spatial columns exist in a given table, along with their SRID and datatype:\n",
    "\n",
    "    SELECT f_geometry_column, srid, type\n",
    "    FROM geometry_columns WHERE\n",
    "    f_table_name = 'tl_2016_us_zcta510';\n",
    "\n",
    "> Reminder: the SRID is the Spatial Reference Identifier, a unique code used in the `spatial_ref_sys` table as described in the Coordinate Reference System section above"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
