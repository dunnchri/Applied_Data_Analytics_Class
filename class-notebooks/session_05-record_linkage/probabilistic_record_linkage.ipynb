{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Record Linkage\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Setup](#Setup)\n",
    "\n",
    "    - [Setup - Imports](#Setup---Imports)\n",
    "    - [Setup - Database connection](#Setup---Database-connection)\n",
    "    \n",
    "- [Data Definition](#Data-Definition)\n",
    "- [String Comparators](#String-Comparators)\n",
    "- [Fellegi-Sunter Record Linkage](#Fellegi-Sunter-Record-Linkage)\n",
    "\n",
    "    - [Value Comparison](#Value-Comparison)\n",
    "    - [Record Comparison](#Record-Comparison)\n",
    "\n",
    "- [Appendix - String Comparators](#Appendix---String-Comparators)\n",
    "- [References & Further Readings](#References-&-Further-Readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this lesson we will learn the basic idea behind probabilistic record linkage.\n",
    "\n",
    "We will use two datasets for this example. The first will be a list of people culled from \"`ildoc_admit`\" and \"`ildoc_exit`\". The second is a set of wage records from \"`il_wage`\".\n",
    "\n",
    "Probabilistic record linkage is somewhat different to deterministic record linkage. It takes into account a wieder range of potential identifiers. Identifiers are not unique anymore, which is why this method is also known as fuzzy matching/merging.It is a method that uses properties of variables commom to different datasets to determine the probability that two records refer to the same entity. Examples of the types of data items that might be compared in this method include gender, date of birth, age, and parts of a name.\n",
    "\n",
    "It computes weights for each idenfier used in the linkage based on the estimated ability to correctly identify a match, or a non-match. Then, by using the estimated weights a probability is calculated that two given records are the same entity. The analyst sets the threshold for this probability to determine when a pairing is defined a match.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fellegi-Sunter Approach\n",
    "\n",
    "This is a popular method used in probabilisitc record linkage. Let's walk through an example how it works\n",
    "\n",
    "- Let's assume each person's wage record matches to one person record in the inmate data and we have 100,000 inmates in our inmate data. Then the odds for a match at random are 1:99,999\n",
    "- M, the reliability is the probability that a commom variable agrees on a matched pair. Approx. 1-error rate\n",
    "- U, the discriminating power is the probability that a commom variable agrees on a unmatched pair. Approx. the probability of aggreeing by chance\n",
    "- If first name is the same: m=0.9, u=0.01, ratio: 90:1, this means that the odds for a matchare now: 1:99,999x90:1=1:1,111\n",
    "- If last name is the same: m=0.9, u=0.04, ratio: 22:1, this means that the odds for a matchare now: 1:1,111x22:1=1:51\n",
    "- And you can add as many variables as possible, such as sex, age, date of birth, etc as long as they are in both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Imports\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Before we start the Probabilistic Record Linkage example, we need to import the packages we will be using.  Please run the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the modules required in this workbook\n",
    "import datetime\n",
    "import jellyfish\n",
    "import math\n",
    "import numpy\n",
    "import pandas\n",
    "import re\n",
    "import six\n",
    "import sqlalchemy\n",
    "import string\n",
    "\n",
    "# Database connection packages - one or the other will be imported below:\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "print( \"imports loaded at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Database connection\n",
    "\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "`Pandas` uses a database engine to connect to databases (via the `SQLAlchemy` Python package).  In the code cell below we create a `SQLAlchemy` database engine connected to our class database server for Pandas to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up database credentials\n",
    "pandas_db = None\n",
    "db_host = \"10.10.2.10\"\n",
    "db_database = \"appliedda\"\n",
    "\n",
    "# Create database connection for pandas.\n",
    "connection_string = \"postgresql://\" + db_host + \"/\" + db_database\n",
    "pandas_db = sqlalchemy.create_engine( connection_string )\n",
    "\n",
    "print( \"sqlalchemy postgresql database engine created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Definition\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Before we begin the task of record linkage, it's important that we understand the variables in our data. In this workbook, we will take a cursory look at some of the values in our data and compute some simple statistics to ensure that the content makes sense. \n",
    "\n",
    "Begin by loading a subset of the data from \"`person`\" and \"`il_wage`\" into pandas data frames. After we load the two data sets, we call the `head` method on the first data set to examine the first few reords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load person data\n",
    "person_df = pandas.read_sql( 'SELECT * FROM person LIMIT 1000;', con = pandas_db )\n",
    "\n",
    "print( \"person data loaded at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wage data\n",
    "il_wage_df = pandas.read_sql( 'SELECT * FROM il_wage WHERE year = 2015 LIMIT 1000;', con = pandas_db )\n",
    "\n",
    "print( \"il_wage data loaded at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close the connection (or \"dispose\" for a SQLAlchemy engine).\n",
    "pandas_db.dispose()\n",
    "\n",
    "print( \"pandas database engine dispose()-ed at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some quick summaries of the fields in the person data.\n",
    "\n",
    "To get a list of the unique values in a pandas column/Series, call the `.unique()` method on it - like `.value_counts()` from last assignment, only not sorted by frequency of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first few records from the person file.\n",
    "person_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the distinct values in the birth_year, race, and sex columns\n",
    "print(\"Distinct years = \", person_df[\"birth_year\"].unique())\n",
    "print(\"Distinct race = \", person_df[\"race\"].unique())\n",
    "print(\"Distinct sex = \", person_df[\"sex\"].unique())\n",
    "\n",
    "# Print the total number of rows and the number of rows with valid SSN,\n",
    "#     first name, middle name, and last name.\n",
    "print( \"Total rows = \", len( person_df ) )\n",
    "\n",
    "ssn_hash = person_df[ \"ssn_hash\" ]\n",
    "print( \"Rows with valid SSN = \" + str( len( ssn_hash[ ~ pandas.isnull( ssn_hash ) ] ) ) )\n",
    "\n",
    "name_first_hash = person_df[ \"name_first_hash\" ]\n",
    "print( \"Rows with valid name_first_hash = \" + str( len( name_first_hash[ ~ pandas.isnull( name_first_hash ) ] ) )  )\n",
    "\n",
    "name_middle_hash = person_df[ \"name_middle_hash\" ]\n",
    "print( \"Rows with valid name_middle_hash = \" + str( len( name_middle_hash[ ~ pandas.isnull( name_middle_hash ) ] ) ) )\n",
    "\n",
    "name_last_hash = person_df[ \"name_last_hash\" ]\n",
    "print( \"Rows with valid name_last_hash = \" + str( len( name_last_hash[ ~ pandas.isnull( name_last_hash ) ] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll take a look at the second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "il_wage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some quick summaries of the fields in the wage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of rows and the number of rows with valid SSN,\n",
    "#     first name, middle name, and last name.\n",
    "print( \"Total rows = \", len( il_wage_df ) )\n",
    "\n",
    "ssn = il_wage_df[ \"ssn\" ]\n",
    "print( \"Rows with valid SSN = \" + str( len( ssn[ ~ pandas.isnull( ssn ) ] ) ) )\n",
    "\n",
    "name_first = il_wage_df[ \"name_first\" ]\n",
    "print( \"Rows with valid name_first = \" + str( len( name_first[ ~ pandas.isnull( name_first ) ] ) ) )\n",
    "\n",
    "name_middle = il_wage_df[ \"name_middle\" ]\n",
    "print( \"Rows with valid name_middle = \" + str( len( name_middle[ ~ pandas.isnull( name_middle ) ] ) ) )\n",
    "\n",
    "name_last = il_wage_df[ \"name_last\" ]\n",
    "print( \"Rows with valid name_last = \" + str( len( name_last[ ~ pandas.isnull( name_last ) ] ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fellegi-Sunter Record Linkage\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fellegi-Sunter Record Linkage is a probabilistic method that uses comparisons of fields that contain the same substantive types of data between records to calculate a weighted probability that records in different data sets refer to the same entity.  Examples of the types of data items that might be compared in this method include gender, date of birth, age, and parts of a name.\n",
    "\n",
    "In this section we will \"manually\" perform the steps in Fellegi-Sunter record linkage. Our goal is to illustrate the Fellegi-Sunter algorithm by breaking it into bitesize pieces. \n",
    "\n",
    "In our example we will compare first names and last names using Jaro-Winkler distance. In the Fellegi-Sunter algorithm, the result of a field comparison is assumed to follow a multinomial distribution. That means it can only take on finitely many values. Therefore we will define a function that compares two strings and returns the value 2, 1, or 0 to indicate an exact match, a nearly exact match, or anything else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Comparison\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this section, we will implement the value comparison stage of Fellegi-Sunter Record Linkage.  You will implement a function named \"`fuzzy-string-comparator`\" that accepts two strings and returns one of the following match levels:\n",
    "\n",
    "- 2 - exact match\n",
    "- 1 - close match\n",
    "- 0 - not a match\n",
    "\n",
    "To assess whether the two strings passed in match, we could convert both strings to capital letters, decode them into unicode, then calculate the Jaro-Winkler distance between the two strings (Jaro-Winkler distance is a fast-to-compute string distance based on common letters between two words).  We then assign a match level based on where the resulting match score falls in the following ranges:\n",
    "\n",
    "- 2 - exact match - score greater than or equal to ( >= ) 0.92\n",
    "- 1 - close match - score less than 0.92 but greater than or equal to 0.85.\n",
    "- 0 - not a match - score less than 0.85.\n",
    "\n",
    "Finally, we'll return that match score.\n",
    "\n",
    "A function that implements this is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "EX2-string_compare",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Please complete the following function that tells us how different two input strings are.\n",
    "# It returns a match level with value 2, 1 or 0 (larger value means higher similarity)\n",
    "# Calculate Jaro-Winkler distance after converting two strings into capital characters.\n",
    "# Please use these three criteria, >=0.92, >=0.85, <0.85, to determine match level.\n",
    "\n",
    "def fuzzy_string_comparator( string_1_IN, string_2_IN ):\n",
    "\n",
    "    '''\n",
    "    string_1_IN : input string No.1\n",
    "    string_2_IN : input string No.2\n",
    "    '''\n",
    "    \n",
    "    # return reference\n",
    "    match_level_OUT = -1\n",
    "\n",
    "    # Check if they are all strings\n",
    "    if ( ( type( string_1_IN ) != str ) or ( type( string_2_IN ) != str ) ):\n",
    "        \n",
    "        match_level_OUT = 0\n",
    "    \n",
    "    #-- END check to see if strings are actually strings. --#\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    # declare variables\n",
    "    cleaned_string_1 = \"\"\n",
    "    cleaned_string_2 = \"\"\n",
    "    distance = -1\n",
    "    \n",
    "    # convert strings to upper case, then to unicode\n",
    "    \n",
    "    # string 1\n",
    "    cleaned_string_1 = string_1_IN.upper()\n",
    "    cleaned_string_1 = six.text_type( cleaned_string_1 )\n",
    "\n",
    "    # string 2\n",
    "    cleaned_string_2 = string_2_IN.upper()\n",
    "    cleaned_string_2 = six.text_type( cleaned_string_2 )\n",
    "    \n",
    "    # Calculate Jaro-Winkler distance after converting two strings into capital characters.\n",
    "    distance = jellyfish.jaro_winkler( cleaned_string_1, cleaned_string_2 )\n",
    "\n",
    "    # According to different thresholds, return the match level\n",
    "    if distance >= 0.92:\n",
    "\n",
    "        match_level_OUT = 2\n",
    "\n",
    "    elif distance >= 0.85:\n",
    "    \n",
    "        match_level_OUT = 1\n",
    "\n",
    "    else:\n",
    "    \n",
    "        match_level_OUT = 0\n",
    "        \n",
    "    #-- END conditional to set match level. --#\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return match_level_OUT\n",
    "\n",
    "#-- END function fuzzy_string_comparator --#\n",
    "\n",
    "print( \"==> Defined function fuzzy_string_comparator() at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "EX2-string_compare-test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's see how the fuzzy_string_comparator works\n",
    "score1 = fuzzy_string_comparator( \"joshua\", \"joshua\" )\n",
    "score2 = fuzzy_string_comparator( \"joshua\", \"joshau\" )\n",
    "score3 = fuzzy_string_comparator( \"joshua\", \"todd\" )\n",
    "\n",
    "print( \"Match level for joshua-joshua: \" + str( score1 ) )\n",
    "print( \"Match level for joshua-joshau: \" + str( score2 ) )\n",
    "print( \"Match level for joshua-todd: \" + str( score3 ) )\n",
    "\n",
    "# tests for our grading program:\n",
    "assert score1 == 2\n",
    "assert score2 == 2\n",
    "assert score3 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function compares *text fields* in a record (other types of data would need different means of comparison). Next, we define a function that compares *records*.  This record comparison function assumes that records will have the form of a tuple: (identifier, first name, last name).  It returns a length 2 tuple that gives the result of applying a string comparator to the first name and to the last name.\n",
    "\n",
    "_Note: Since our name values are hashed, we've replaced the fuzzy match call here with a simple equality test, since hash values being close together doesn't indicate that the names from which they were generated are close._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison_vector compare a pair of records, which consists of first name and last name.\n",
    "# It returns a tuple with 2 match levels.\n",
    "\n",
    "def compare_records( record_1_IN, record_2_IN ):\n",
    "\n",
    "    '''\n",
    "    record_1_IN : input record No.1\n",
    "    record_2_IN : input record No.2\n",
    "    '''\n",
    "    \n",
    "    # return reference\n",
    "    results_OUT = None\n",
    "    \n",
    "    # declare variables\n",
    "    value_1 = None\n",
    "    value_2 = None\n",
    "    field_1_match_level = -1\n",
    "    field_2_match_level = -1\n",
    "    \n",
    "    # record_1_IN and record_2_IN have the form (id, first name, last name)\n",
    "    \n",
    "    # m, n store the comparing outcomes of first name and last name.\n",
    "    value_1 = record_1_IN[ 1 ]\n",
    "    value_2 = record_2_IN[ 1 ]\n",
    "    if ( ( value_1 is not None ) and ( value_2 is not None ) ):\n",
    "    \n",
    "        #field_1_match_level = fuzzy_string_comparator( value_1, value_2 )\n",
    "        # just check equality since hash.\n",
    "        if ( value_1 == value_2 ):\n",
    "            \n",
    "            field_1_match_level = 2\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            field_1_match_level = 0\n",
    "            \n",
    "        #-- END check to see if equal or not. --#\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        field_1_match_level = 0\n",
    "        \n",
    "    #-- END check to see if empty values. --#\n",
    "    \n",
    "    value_1 = record_1_IN[ 2 ]\n",
    "    value_2 = record_2_IN[ 2 ]\n",
    "    if ( ( value_1 is not None ) and ( value_2 is not None ) ):\n",
    "    \n",
    "        #field_2_match_level = fuzzy_string_comparator( value_1, value_2 )\n",
    "        # just check equality since hash.\n",
    "        if ( value_1 == value_2 ):\n",
    "            \n",
    "            field_2_match_level = 2\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            field_2_match_level = 0\n",
    "            \n",
    "        #-- END check to see if equal or not. --#\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        field_2_match_level = 0\n",
    "        \n",
    "    #-- END check to see if empty values. --#\n",
    "   \n",
    "    results_OUT = ( field_1_match_level, field_2_match_level )\n",
    "\n",
    "    return results_OUT\n",
    "\n",
    "#-- END function compare_records() --#\n",
    "\n",
    "print( \"==> Defined function compare_records() at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try out the compare_records function\n",
    "\n",
    "print( compare_records( ( 1, \"joshua\", \"tokle\" ), ( 2, \"joshua\", \"smith\") ) )\n",
    "print( compare_records( ( 3, \"joshua\", \"tokle\" ), ( 4, \"josue\", \"tolke\") ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Comparison\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Next, we'll work on implementing the section of Fellegi-Sunter Record Linkage that calculates a weighted probability that two records from different data sets refer to the same entity.\n",
    "\n",
    "Fellegi-Sunter Record Linkage uses two different sets of probabilities per pair of data items as weights in this step: m-weights and u-weights.\n",
    "\n",
    "For a given pair of data items that represent the same conceptual thing, for each match level:\n",
    "- An **m-weight** is the probability of seeing a particular match level if we assume that we are comparing two records that represent the same individual.\n",
    "- A **u-weight** is the probability of seeing a particular match level if we assume that that we are comparing two records that do *not* represent the same individual.\n",
    "\n",
    "For example, thinking of probabilities when two records are the same (m-weights), if two records represent the same person, the first names and last names should match with high probability - match level 2.  So, the m-weight for first name and last name having a match level of 2 when two records refer to the same person should be large.\n",
    "\n",
    "On the other hand, in the context of probabilities when two records are different (u-weights), suppose we had month of birth in our data set.  The probability that two random individuals will have the same month of birth is about 1/12, so for records that are not the same person, we would assign a u-weight of about 1/12 to the birth year being identical (where for a field like social security number, the u-weight of two different people having the same social security number is 0).\n",
    "\n",
    "Let's assign some preliminary and arbitrary m- and u-weights for first name and last name.\n",
    "\n",
    "- first name\n",
    "\n",
    "    - m-weights:\n",
    "\n",
    "        - match level 0: **_0.01_** (very unlikely the same person will have different first names)\n",
    "        - match level 1: **_0.14_** (also pretty unlikely that first names for a person will be mostly the same)\n",
    "        - match level 2: **_0.85_** (very likely that a person's first names will match exactly)\n",
    "\n",
    "    - u-weights:\n",
    "\n",
    "        - match level 0: **_0.88_** (probability that different people will have different first names)\n",
    "        - match level 1: **_0.10_** (probability that different people's first names will be mostly the same)\n",
    "        - match level 2: **_0.02_** (probability that different people will have same first name)\n",
    "- last name\n",
    "\n",
    "    - m-weights:\n",
    "\n",
    "        - match level 0: **_0.01_** (very unlikely the same person will have different last names)\n",
    "        - match level 1: **_0.09_** (also pretty unlikely that last names for a person will be mostly the same)\n",
    "        - match level 2: **_0.90_** (very likely that a person's last names will match exactly)\n",
    "\n",
    "    - u-weights:\n",
    "\n",
    "        - match level 0: **_0.91_** (probability that different people will have different first names)\n",
    "        - match level 1: **_0.08_** (probability that different people's first names will be mostly the same)\n",
    "        - match level 2: **_0.01_** (probability that different people will have same first name\n",
    "    \n",
    "In practice you would likely start with guesses or very general estimates like these, but then try to better estimate these by trying to fit them to a model or at least tweaking them after seeing preliminary output. In this case, we are just going to run with our initial estimates so we can move efficiently through this process.\n",
    "\n",
    "In the cell below, we create dictionaries that contain the m- and u-weights for our two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionaries to hold m_weights and u-weights.  In each dictionary, the weights for\n",
    "#    a given field are mapped to a string label for that field (\"first_name\" and \"last_name\").\n",
    "# Weights are captured in tuples of length 3, with the index in the tuple matching each of the \n",
    "#   match levels that can be returned by the fuzzy string comparator.\n",
    "# In this tuple, we go from match level 0 (not the same), to match level 2 (identical)\n",
    "#    as we move from left to right in the tuple, with each position in the tuple holding the\n",
    "#    corresponding weight for that match level.\n",
    "\n",
    "m_weights_dict = {}\n",
    "m_weights_dict[ \"first_name\" ] = ( 0.01, 0.14, 0.85 )  # m-weights corresponding to first name\n",
    "m_weights_dict[ \"last_name\" ] = ( 0.01, 0.09, 0.90 ) # m-weights corresponding to last name\n",
    "\n",
    "u_weights_dict = {}\n",
    "u_weights_dict[ \"first_name\" ] = ( 0.88, 0.10, 0.02 ) # u-weights corresponding to first name\n",
    "u_weights_dict[ \"last_name\" ] = ( 0.91, 0.08, 0.01 ) # u-weights corresponding to last name\n",
    "\n",
    "print( \"==> Created m- and u-weight dictionaries at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for exercise 3, we are going to define a function that uses these weights to compare two records and return their record-level match score.\n",
    "\n",
    "In Fellegi-Sunter Record Linkage the match score for a given record is the at calculates a weighted probability that two records from different data sets refer to the same entity.\n",
    "\n",
    "The match_score function starts by comparing the two records passed in and retrieving a match level for the first name and last name.  The function then needs to:\n",
    "\n",
    "- get tuples of m- and u-weights for first name and last name.\n",
    "- retrieve the m- and u-weights for the particular match level calculated for first and last name.\n",
    "- calculate the \"log probability\" of each of the weights retrieved in the previous step.  The \"log probability\" of a probability is the log base-n of that probability - so, the result of calling the \"`math.log()`\" function on a probability (in this case, on each of the weights we retrieved in the step above).\n",
    "- use these log probabilities to calculate a match score for the first name and the second name.  Our algorithm for this match score:\n",
    "\n",
    "    - sum the log probabilities of the records being a match (the log probabilities of the m-weights).\n",
    "    - sum the log probabilities of the records not being a match (the log probabilities of the u-weights).\n",
    "    - subtract the non-match (u-weight) sum from the match (m-weight) sum.\n",
    "    \n",
    "- store your match score value in the variable \"`score_OUT`\" so that it is returned by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_score( record_1_IN, record_2_IN ):\n",
    "\n",
    "    '''\n",
    "    record_1_IN: input record No.1\n",
    "    record_2_IN: input record No.2\n",
    "    '''\n",
    "    \n",
    "    # return reference\n",
    "    score_OUT = -1\n",
    "    \n",
    "    # declare variables\n",
    "    match_level_tuple = None\n",
    "    match_level_first_name = -1\n",
    "    match_level_last_name = -1\n",
    "    \n",
    "    # Calulate the similarity level using compare_records\n",
    "    match_level_tuple = compare_records( record_1_IN, record_2_IN )\n",
    "    match_level_first_name = match_level_tuple[ 0 ]\n",
    "    match_level_last_name = match_level_tuple[ 1 ]\n",
    "    \n",
    "    # Use match levels and m- and u-weights to calculate a match score for this record.\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # declare variables\n",
    "    m_weights_list_first_name = None\n",
    "    m_weights_list_last_name = None\n",
    "    u_weights_list_first_name = None\n",
    "    u_weights_list_last_name = None\n",
    "    first_name_m_weight = -1\n",
    "    first_name_u_weight = -1\n",
    "    last_name_m_weight = -1\n",
    "    last_name_u_weight = -1\n",
    "    log_prob_given_match = None\n",
    "    log_prob_given_nonmatch = None\n",
    "    \n",
    "    # get lists of m- and u- weights for each field from weights dictionaries defined above.\n",
    "    m_weights_list_first_name = m_weights_dict[ \"first_name\" ]\n",
    "    m_weights_list_last_name = m_weights_dict[ \"last_name\" ]\n",
    "    u_weights_list_first_name = u_weights_dict[ \"first_name\" ]\n",
    "    u_weights_list_last_name = u_weights_dict[ \"last_name\" ]\n",
    "   \n",
    "    # get weights for match levels returned by compare_records.\n",
    "    first_name_m_weight = m_weights_list_first_name[ match_level_first_name ]\n",
    "    first_name_u_weight = u_weights_list_first_name[ match_level_first_name ]\n",
    "    last_name_m_weight = m_weights_list_last_name[ match_level_last_name ]\n",
    "    last_name_u_weight = u_weights_list_last_name[ match_level_last_name ]\n",
    "    \n",
    "    # calculate log-probabilities for each field assuming a match (m-weight),\n",
    "    #    and assuming a non-match (u-weight).  Log-probability is the natural\n",
    "    #    log (math.log() in Python) of the probability of a given match level.\n",
    "    log_prob_first_name_given_match = math.log( first_name_m_weight )\n",
    "    log_prob_last_name_given_match = math.log( last_name_m_weight )\n",
    "    log_prob_first_name_given_no_match = math.log( first_name_u_weight )\n",
    "    log_prob_last_name_given_no_match = math.log( last_name_u_weight )\n",
    "    \n",
    "    # For match and no-match, sum the log-probabilities for each field.\n",
    "    \n",
    "    # What's the log-probability of seeing this comparison vector if the records are a match?\n",
    "    log_prob_given_match = log_prob_first_name_given_match + log_prob_last_name_given_match\n",
    "    \n",
    "    # What's the log-probability of seeing this comparison vector if the records are a nonmatch?\n",
    "    log_prob_given_nonmatch = log_prob_first_name_given_no_match + log_prob_last_name_given_no_match\n",
    "    \n",
    "    # match score is the sum of the log probabilities given a match\n",
    "    #    minus the sum of the log probabilites given no match.\n",
    "    score_OUT = log_prob_given_match - log_prob_given_nonmatch\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # return match score.\n",
    "    return score_OUT\n",
    "\n",
    "#-- END function match_score() --#\n",
    "\n",
    "print( \"==> Defined function match_score() at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a rough look at its sample output\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (2, \"joshua\", \"smith\")))\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (4, \"joshu\", \"tolke\")))\n",
    "print(match_score((1, \"joshua\", \"tokle\"), (7, \"christina\", \"jones\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can try to link people in our \"`person`\" table with \"`il_wage`\" records.\n",
    "\n",
    "We use our \"`match_score()`\" function to compare each name in the person list with each name in the wage record list, storing only matches whose score exceeds a threshold (0.5, to start) in a separate list of potential matches.\n",
    "\n",
    "_Note: This code cell might take quite a few minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a few minutes to execute\n",
    "\n",
    "# configuration\n",
    "match_score_min = 0.5\n",
    "\n",
    "# Create an empty list to save the outputs\n",
    "potential_matches = []\n",
    "\n",
    "# Loop over uc data frame by row\n",
    "person_counter = 0\n",
    "for person_index, person_row in person_df.iterrows():\n",
    "\n",
    "    # increment counter\n",
    "    person_counter += 1\n",
    "    \n",
    "    # Get ID, FirstName and LastName of uc\n",
    "    current_person_id = person_row[ \"id\" ]\n",
    "    current_person_first_name = person_row[ \"name_first_hash\" ]\n",
    "    current_person_last_name = person_row[ \"name_last_hash\" ]\n",
    "\n",
    "    # store in tuple for comparison\n",
    "    current_person_record = ( current_person_id, current_person_first_name, current_person_last_name )\n",
    "    \n",
    "    #print( \"==> Processing UC person \" + str( person_counter ) + \": \" + str( current_person_record ) )\n",
    "    \n",
    "    # Loop over wage data frame by lines\n",
    "    wage_counter = 0\n",
    "    for wage_index, wage_row in il_wage_df.iterrows():    \n",
    "\n",
    "        # increment counter\n",
    "        wage_counter += 1\n",
    "\n",
    "        # Get id, name_first and name_last from NSF row.\n",
    "        current_wage_id = wage_row[ \"id\" ] # no person ID, so using id.\n",
    "        current_wage_first_name = wage_row[ \"name_first\" ]\n",
    "        current_wage_last_name = wage_row[ \"name_last\" ]\n",
    "\n",
    "        # store in tuple for comparison\n",
    "        current_wage_record = ( current_wage_id, current_wage_first_name, current_wage_last_name )\n",
    "\n",
    "        # print( \"====> Processing wage person \" + str( wage_counter ) + \": \" + str( current_wage_record ) )\n",
    "\n",
    "        # Calculate the match score of each pair of records\n",
    "        score = match_score( current_person_record, current_wage_record )\n",
    "\n",
    "        # Save those pairs with score equal to or greater than 0.5\n",
    "        if score >= match_score_min:\n",
    "            \n",
    "            # good enough - add to potential_matches\n",
    "            potential_matches.append( ( score, current_person_record, current_wage_record ) )\n",
    "            \n",
    "        #-- END conditional to see if score is above our threshold --#\n",
    "        \n",
    "    #-- END loop over wage data frame rows. --#\n",
    "    \n",
    "    # output a little message every 1000 rows.\n",
    "    if ( person_counter % 1000 == 0 ):\n",
    "        \n",
    "        print( \"==> Processed \" + str( current_wage_record ) + \" of \" + str( len( person_df ) ) + \" person records.\" )\n",
    "        \n",
    "    #-- END check to see if we've processed another thousand rows yet. --#\n",
    "\n",
    "#-- END loop over UC data frame rows. --#\n",
    "        \n",
    "# Sort the output so the best matches appear at the top\n",
    "\n",
    "# define lambda to retrieve score from each tuple (first item in tuple)\n",
    "lambda_get_score = lambda x: x[0]\n",
    "\n",
    "# sort\n",
    "potential_matches = sorted( potential_matches, key = lambda_get_score, reverse = True )\n",
    "\n",
    "# output matches:\n",
    "print( \"Matches, in order of descending match score:\" )\n",
    "for current_match in potential_matches:\n",
    "    \n",
    "    # print current match.\n",
    "    print( \"==> \" + str( current_match ) )\n",
    "\n",
    "#-- END output loop. --#\n",
    "    \n",
    "# How did we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we assess the potential matches displayed above - how did our algorithm do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - String Comparators\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In this section we will demonstrate different string comparison algorithms provided by the [jellyfish](https://github.com/sunlightlabs/jellyfish) package ( [https://github.com/sunlightlabs/jellyfish](https://github.com/sunlightlabs/jellyfish) ).\n",
    "\n",
    "For each method we examine, we'll write a function that accepts a name that we want to find matches for and a list of names in which we should look, and that returns a list of the names in that list that are most similar to the name of interest.\n",
    "\n",
    "We will start by creating a `set` of unique first names from the \"`il_wage`\" data. The `name_first_hash` field is missing some values which are represented as NaN in the data frame. To prevent errors later on, we only include valid character strings (which have type `str`) in our list of unique names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were starting from scratch, we'd need to import jellyfish\n",
    "# import jellyfish\n",
    "\n",
    "# Make a set storing the unique first name with respect to the nsf dataset\n",
    "unique_first_names = set( name for name in il_wage_df[ \"name_first_hash\" ] if type( name ) == six.text_type )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our function \"`closest_names`\" that:\n",
    "\n",
    "* Accepts a string name we are interested in matching as input argument \"`name_IN`\".\n",
    "+ Accepts a list of names in which we want to look for \"`name_IN`\", in argument \"`find_name_in_list_IN`\".\n",
    "* Accepts an optional number of results we want returned as input argument \"`result_count_IN`\".\n",
    "* Compares the name in `name_IN` to each name in `unique_first_names` and calculates the \"distance\" between the two strings using the Levenshtein Distance string comparator from `jellyfish`.\n",
    "* Return a list of size `result_count_IN` of names in `uniq_first_names` that are \"closest\" to `name_IN`.\n",
    "\n",
    "From wikipedia, the Levenshtein Distance is defined as:\n",
    "\n",
    "> \"In information theory and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other. It is named after Vladimir Levenshtein, who considered this distance in 1965.\"\n",
    "\n",
    "> &mdash; [https://en.wikipedia.org/wiki/Levenshtein_distance](https://en.wikipedia.org/wiki/Levenshtein_distance)\n",
    "\n",
    "_Note that in the comparison we capitalize both names being compared, so that letter case doesn't affect the final distance._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_names( name_IN, find_name_in_list_IN, result_count_IN = 10 ):\n",
    "\n",
    "    # return reference\n",
    "    results_OUT = []\n",
    "    \n",
    "    # declare variables\n",
    "    other_name = \"\"\n",
    "    cleaned_name = \"\"\n",
    "    cleaned_other_name = \"\"\n",
    "    get_distance_lambda = None\n",
    "    \n",
    "    # first, standardize the name - convert to upper case and to unicode.\n",
    "    cleaned_name = name_IN.upper()\n",
    "    cleaned_name = six.text_type( cleaned_name )\n",
    "    \n",
    "    # First create a list of tuples (other_name, distance), where other_name is taken from uniq_first_names\n",
    "    distances = []\n",
    "\n",
    "    # loop over unique_first_names to calculate and store distances\n",
    "    for other_name in find_name_in_list_IN:\n",
    "        \n",
    "        # standardize the other name.\n",
    "        cleaned_other_name = other_name.upper()\n",
    "        cleaned_other_name = six.text_type( cleaned_other_name )\n",
    "        \n",
    "        # get distance from name to other_name (converted to upper case so we are case-insensitive.)\n",
    "        distance_value = jellyfish.levenshtein_distance( cleaned_name, cleaned_other_name )\n",
    "        \n",
    "        # add tuple to distances\n",
    "        current_tuple = ( other_name, distance_value )\n",
    "        distances.append( current_tuple )\n",
    "    \n",
    "    #-- END loop over unique_first_names --#\n",
    "    \n",
    "    # Sort distances by the second element in the tuple.\n",
    "    \n",
    "    # define lambda function to retrieve the distance (the second item in the tuple)\n",
    "    #    and return it.  Lambda functions are little one line functions.  More information:\n",
    "    #    https://docs.python.org/2/reference/expressions.html#lambda\n",
    "    get_distance_lambda = lambda distance_tuple_list_IN : distance_tuple_list_IN[ 1 ]\n",
    "    \n",
    "    # sort matching names by distance\n",
    "    results_OUT = sorted( distances, key = get_distance_lambda )\n",
    "    \n",
    "    # get the number of results requested using Python's slice notation.\n",
    "    results_OUT = results_OUT[ : result_count_IN ]\n",
    "    \n",
    "    # return results\n",
    "    return results_OUT\n",
    "    \n",
    "    '''\n",
    "    # For reference, compacted version - you can do this, but please don't.\n",
    "    \n",
    "    # First create a list of tuples (other_name, distance), where other_name is taken from uniq_first_names\n",
    "    distances = [ ( other_name, jellyfish.levenshtein_distance( unicode( name_IN.upper() ), unicode( other_name.upper() ) ) )\n",
    "        for other_name in unique_first_names ]\n",
    "\n",
    "    # Sort distances by the second element in the tuple, and return the top n values\n",
    "    return sorted(distances, key=lambda x: x[1])[:result_count_IN]\n",
    "    '''\n",
    "\n",
    "#-- END function closest_names() --#\n",
    "\n",
    "print( \"==> Defined function closest_names() at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on some names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment the function with several names.\n",
    "print( closest_names( \"Jennifer\", unique_first_names ) )\n",
    "print( closest_names( \"Sonya\", unique_first_names ) )\n",
    "print( closest_names( \"Wai Tong\", unique_first_names ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that Levenshtein distance is a kind of edit distance. Edit distances count the number of edit operations needed to change one word to another, and different edit distances count different edit operations as valid. In the case of Levenshtein distance, the valid edit operations are inserting a letter, deleting a letter, or changing a letter. \n",
    "\n",
    "It would be interesting to compare this output to the output from other string comparators included in the jellyfish package:\n",
    "\n",
    "* **`jellyfish.lenvenshtein_distance`** - _Levenshtein distance_: edit distance where the valid operations are inserting a letter, deleting a letter, or changing a letter\n",
    "* **`jellyfish.damerau_levenshtein_distance`** - _Levenshtein-Damerau distance_: edit distance which includes the same operations as Levenshtein distance but also allows transposing two adjacent letters. This can be useful for finding words with typos.\n",
    "* **`jellyfish.jaro_winkler`** - _Jaro-Winkler distance_: a fast-to-compute string distance based on common letters between two words\n",
    "\n",
    "_Note: For edit distance smaller numbers indicate closer strings, but for Jaro-Winkler distance larger values indicate closer strings._\n",
    "\n",
    "Let's update our `closest_names` function so that we can specify the string comparator we want to use.  Changes from previous function:\n",
    "\n",
    "- add ability to pass in the string distance calculation function you want to use as an argument, named \"`string_comparator_function_IN`\".\n",
    "\n",
    "    - just pass the name of the function, not in quotation marks, and not followed by parentheses (just like they are shown in the list of functions above).\n",
    "\n",
    "- add ability to reverse sort order for returning \"closest\" strings to name passed in.  New parameter \"`reverse_sort_IN`\" defaults to `False` (to match distance scores where a larger number indicates two strings being further apart).  Set it to `True` for distance scores like Jaro-Winkler distance where a larger number indicates two strings are closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_names_2( string_comparator_function_IN, name_IN, find_name_in_list_IN, reverse_sort_IN = False, result_count_IN = 10 ):\n",
    "\n",
    "    # return reference\n",
    "    results_OUT = []\n",
    "    \n",
    "    # declare variables\n",
    "    other_name = \"\"\n",
    "    cleaned_name = \"\"\n",
    "    cleaned_other_name = \"\"\n",
    "    get_distance_lambda = None\n",
    "    \n",
    "    # first, standardize the name - convert to upper case and to unicode.\n",
    "    cleaned_name = name_IN.upper()\n",
    "    cleaned_name = six.text_type( cleaned_name )\n",
    "    \n",
    "    # First create a list of tuples (other_name, distance), where other_name is taken from uniq_first_names\n",
    "    distances = []\n",
    "\n",
    "    # loop over unique_first_names to calculate and store distances\n",
    "    for other_name in find_name_in_list_IN:\n",
    "        \n",
    "        # standardize the other name.\n",
    "        cleaned_other_name = other_name.upper()\n",
    "        cleaned_other_name = six.text_type( cleaned_other_name )\n",
    "        \n",
    "        # get distance from name to other_name (converted to upper case so we are case-insensitive.)\n",
    "        distance_value = string_comparator_function_IN( cleaned_name, cleaned_other_name )\n",
    "        \n",
    "        # add tuple to distances\n",
    "        current_tuple = ( other_name, distance_value )\n",
    "        distances.append( current_tuple )\n",
    "    \n",
    "    #-- END loop over unique_first_names --#\n",
    "    \n",
    "    # Sort distances by the second element in the tuple.\n",
    "    \n",
    "    # define lambda function to retrieve the distance (the second item in the tuple)\n",
    "    #    and return it.  Lambda functions are little one line functions.  More information:\n",
    "    #    https://docs.python.org/2/reference/expressions.html#lambda\n",
    "    get_distance_lambda = lambda distance_tuple_list_IN : distance_tuple_list_IN[ 1 ]\n",
    "    \n",
    "    # sort matching names by distance\n",
    "    results_OUT = sorted( distances, key = get_distance_lambda, reverse = reverse_sort_IN )\n",
    "    \n",
    "    # get the number of results requested using Python's slice notation.\n",
    "    results_OUT = results_OUT[ : result_count_IN ]\n",
    "    \n",
    "    # return results\n",
    "    return results_OUT\n",
    "    \n",
    "    '''\n",
    "    # For reference, compacted version - you can do this, but please don't.\n",
    "    \n",
    "    # First create a list of tuples (other_name, distance), where other_name is taken from uniq_first_names\n",
    "    distances = [(other_name, string_comparator(unicode(name.upper()), unicode(other_name.upper())))\n",
    "                 for other_name in uniq_first_names]\n",
    "    \n",
    "    # Sort distances by the second element in the tuple, and return the top n values\n",
    "    return sorted(distances, key=lambda x: x[1], reverse=reverse_sort)[:n]\n",
    "    '''\n",
    "\n",
    "#-- END function closest_names_2() --#\n",
    "\n",
    "print( \"==> Defined function closest_names_2() at \" + str( datetime.datetime.now() ) + \".\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it!\n",
    "print( \"Closest names for \\\"William\\\" using Levenshtein-Damerau distance:\" )\n",
    "print( closest_names_2( jellyfish.damerau_levenshtein_distance, \"William\", unique_first_names ) )\n",
    "\n",
    "print( \"\\n\\nClosest names for \\\"William\\\" using Levenshtein-Damerau distance:\" )\n",
    "print( closest_names_2( jellyfish.jaro_winkler, \"Wiliam\", unique_first_names, reverse_sort_IN = True ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References & Further Readings\n",
    "\n",
    "- Back to the [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "### Parsing\n",
    "\n",
    "* Python online documentation: https://docs.python.org/2/library/string.html#deprecated-string-functions\n",
    "* Python 2.7 Tutorial(Splitting and Joining Strings): http://www.pitt.edu/~naraehan/python2/split_join.html\n",
    "\n",
    "### Regular Expression\n",
    "\n",
    "* Python documentation: https://docs.python.org/2/library/re.html#regular-expression-syntax\n",
    "* Online regular expression tester (good for learning): http://regex101.com/\n",
    "\n",
    "### String Comparators\n",
    "\n",
    "* GitHub page of jellyfish: https://github.com/jamesturk/jellyfish\n",
    "* Different distances that measure the differences between strings:\n",
    "    - Levenshtein distance: https://en.wikipedia.org/wiki/Levenshtein_distance\n",
    "    - Damerau–Levenshtein distance: https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "    - Jaro–Winkler distance: https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n",
    "    - Hamming distance: https://en.wikipedia.org/wiki/Hamming_distance\n",
    "    - Match rating approach: https://en.wikipedia.org/wiki/Match_rating_approach\n",
    "\n",
    "### Fellegi-Sunter Record Linkage \n",
    "\n",
    "* Introduction to Probabilistic Record Linkage: http://www.bristol.ac.uk/media-library/sites/cmm/migrated/documents/problinkage.pdf\n",
    "* Paper Review: https://www.cs.umd.edu/class/spring2012/cmsc828L/Papers/HerzogEtWires10.pdf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
